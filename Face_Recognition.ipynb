{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4depaApLAoVga2QVsK3/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umeshtik3/Data-Science-Projects/blob/master/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EaWMUG51qMt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h_cErGu20dK"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjHTmfK63ds0"
      },
      "source": [
        "cd '/content/gdrive/My Drive/Friends/Bandra/kalsubai'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0JQnL2v5RZ3"
      },
      "source": [
        "!pwd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN6TbQ7-5YJE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.feature import hog\n",
        "from skimage import data,exposure\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcOpGER53gu"
      },
      "source": [
        "#read image from disk \n",
        "image1 = cv2.imread('IMG_0336.JPG')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sHxR6zF7xw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug0socSb8ZoA"
      },
      "source": [
        "image1 = cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fd,hog_image = hog(image1,orientations=8,pixels_per_cell=(16,16),cells_per_block=(1,1),visualize=True,multichannel=True)\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(1, 2,figsize = (8,4),sharex=True,sharey=True  )\n",
        "ax1.axis('Off')\n",
        "ax1.imshow(image1,cmap=plt.cm.gray)\n",
        "ax1.set_title('input image')\n",
        "\n",
        "\n",
        "hog_image_rescaled = exposure.rescale_intensity(hog_image,in_range=(0,10))\n",
        "ax2.axis('Off')\n",
        "ax2.imshow(hog_image_rescaled,cmap=plt.cm.gray)\n",
        "ax2.set_title('Histogram of oriented Gradients')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuIdvHgqQF5r"
      },
      "source": [
        "face_loc = face_recognition.face_locations(image1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0s2Fh5QQsIM"
      },
      "source": [
        "number_of_faces = len(face_loc)\n",
        "print(f'found {number_of_faces} faces in image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWLHDtc5Rfz7"
      },
      "source": [
        "def f_dect() :\n",
        "    plt.imshow(image1)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for fl in face_loc:\n",
        "      top,right,bottom,left = fl\n",
        "      x,y,w,h = left,top,right,bottom\n",
        "      print(f'a face is located at pixel location Top :{x},Left : {y},Bottom:{w},Right:{h}')\n",
        "\n",
        "      rect = Rectangle((x,y),w-x,h-y,fill=False,color = 'red')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqodi0UB9zTG"
      },
      "source": [
        "Face Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIJChXYP9z2O"
      },
      "source": [
        "import face_recognition\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "import numpy as np\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBTGqrIO8aN"
      },
      "source": [
        "#loading images of databases\n",
        "\n",
        "\n",
        "my_image = cv2.imread('IMG_001.JPG')\n",
        "my_image = cv2.cvtColor(my_image,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "my_image2 = cv2.imread('IMG_004.JPG')\n",
        "my_image2 = cv2.cvtColor(my_image2,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVbwQKfgX7dG"
      },
      "source": [
        "#face_encoding2 =  face_recognition.face_encodings(dev_image)[0]\n",
        "face_encoding3 = face_recognition.face_encodings(my_image)[0]\n",
        "face_encoding4 = face_recognition.face_encodings(my_image1)[0]\n",
        "#face_encoding5 = face_recognition.face_encodings(my_image2)[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "known_faces = [face_encoding3,face_encoding4]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xNNMSwUbxsC"
      },
      "source": [
        "ui = cv2.imread('mypic.jpg')\n",
        "ui=cv2.cvtColor(ui,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(ui)\n",
        "unknown_encoding = face_recognition.face_encodings(ui)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reg_004IHs2_"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "for i in unknown_encoding:\n",
        "  results = []\n",
        "  for y in known_faces:\n",
        "    d = distance.euclidean(y,i)\n",
        "    results.append(d)\n",
        "  threshold = 0.6\n",
        "  results = np.array(results) <= threshold\n",
        "\n",
        "\n",
        "  name = 'unknown'\n",
        "\n",
        "  if results[0]:\n",
        "    name = 'suraj'\n",
        "  elif results[1]:\n",
        "    name = 'umesh'\n",
        "    \n",
        "  else:\n",
        "    name = 'not found'\n",
        "  \n",
        "  print(f'found {name} ')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}